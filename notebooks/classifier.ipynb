{
 "cells": [
  {
   "cell_type": "code",
   "id": "d10c1baad49c161f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:26:53.125808Z",
     "start_time": "2025-01-26T17:26:52.382516Z"
    }
   },
   "source": [
    "import os\n",
    "import kagglehub\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from src import ImageClassifier"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladyoslav/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "ebd29ff674f16f6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:26:54.214736Z",
     "start_time": "2025-01-26T17:26:53.130084Z"
    }
   },
   "source": [
    "# Load dataset\n",
    "path = os.path.join(\n",
    "    kagglehub.dataset_download(\"rahmasleam/intel-image-dataset\"), \"Intel Image Dataset\"\n",
    ")\n",
    "print(\"Dataset path:\", path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: /Users/vladyoslav/.cache/kagglehub/datasets/rahmasleam/intel-image-dataset/versions/1/Intel Image Dataset\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "aaf411c6e61706d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:26:54.337950Z",
     "start_time": "2025-01-26T17:26:54.335889Z"
    }
   },
   "source": [
    "# Get list of categories\n",
    "categories = list(filter(lambda category: category != \".DS_Store\", os.listdir(path)))\n",
    "print(\"Categories:\", categories)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories: ['forest', 'buildings', 'glacier', 'street', 'mountain', 'sea']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "e2285743aba2fd2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:26:54.344743Z",
     "start_time": "2025-01-26T17:26:54.342367Z"
    }
   },
   "source": [
    "# Function to get image arrays and labels\n",
    "def get_image_arrays(dataset_path):\n",
    "    \"\"\"\n",
    "    Retrieve the image arrays and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        dataset_path (str): Path to the root folder containing images.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two lists:\n",
    "            - List of image arrays (np.ndarray).\n",
    "            - List of labels for each image.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(dataset_path, category)\n",
    "        for img_file in os.listdir(category_path):\n",
    "            img_path = os.path.join(category_path, img_file)\n",
    "            if os.path.isfile(img_path) and img_path.lower().endswith(\n",
    "                (\".png\", \".jpg\", \".jpeg\")\n",
    "            ):\n",
    "                image = cv2.imread(img_path)\n",
    "                if image is not None:  # Ensure the image was successfully loaded\n",
    "                    images.append(image)\n",
    "                    labels.append(category)\n",
    "\n",
    "    return images, labels"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "669b69fc16c240dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:27:58.278521Z",
     "start_time": "2025-01-26T17:26:54.357058Z"
    }
   },
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Get all image arrays and labels\n",
    "images, labels = get_image_arrays(path)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "    images, labels, test_size=0.2, random_state=52\n",
    ")\n",
    "\n",
    "# Initialize the classifier\n",
    "classifier = ImageClassifier()\n",
    "\n",
    "# Train the model on the training set\n",
    "classifier.fit(train_images, train_labels)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from images...\n",
      "Training the Random Forest classifier...\n",
      "Training complete!\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "3caec1d599080496",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:31:50.339362Z",
     "start_time": "2025-01-26T17:31:50.301492Z"
    }
   },
   "source": [
    "# Predict and evaluate the F1 score on the test set\n",
    "y_true = []\n",
    "y_pred = []\n",
    "category_stats = {\n",
    "    category: {\"total\": 0, \"correct\": 0, \"incorrect\": 0} for category in categories\n",
    "}\n",
    "\n",
    "# Loop through the test images and predict their categories\n",
    "for img, true_label in tqdm(zip(test_images, test_labels), total=len(test_images)):\n",
    "    # Get predicted probabilities and categorize the result\n",
    "    predicted_probs = classifier.predict(img)\n",
    "    predicted_label = max(predicted_probs, key=predicted_probs.get)\n",
    "\n",
    "    # Add true and predicted labels to lists\n",
    "    y_true.append(true_label)\n",
    "    y_pred.append(predicted_label)\n",
    "\n",
    "    # Update category statistics\n",
    "    category_stats[true_label][\"total\"] += 1\n",
    "    if predicted_label == true_label:\n",
    "        category_stats[true_label][\"correct\"] += 1\n",
    "    else:\n",
    "        category_stats[true_label][\"incorrect\"] += 1"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for prediction...\n",
      "{'forest': np.float64(0.26), 'buildings': np.float64(0.06), 'glacier': np.float64(0.11), 'street': np.float64(0.03), 'mountain': np.float64(0.07), 'sea': np.float64(0.47)}\n",
      "sea\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "5872a2e54a5d3217",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:28:16.401473Z",
     "start_time": "2025-01-26T17:28:16.395744Z"
    }
   },
   "source": [
    "# Calculate F1 score\n",
    "f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "print(f\"Overall F1 score: {f1:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall F1 score: 0.1691\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-26T17:28:16.440788Z",
     "start_time": "2025-01-26T17:28:16.432360Z"
    }
   },
   "source": [
    "# Prepare the category-wise report\n",
    "report_data = []\n",
    "for category in categories:\n",
    "    total = category_stats[category][\"total\"]\n",
    "    correct = category_stats[category][\"correct\"]\n",
    "    incorrect = category_stats[category][\"incorrect\"]\n",
    "    accuracy_category = correct / total if total > 0 else 0\n",
    "    report_data.append(\n",
    "        {\n",
    "            \"Category\": category,\n",
    "            \"Total\": total,\n",
    "            \"Correct\": correct,\n",
    "            \"Incorrect\": incorrect,\n",
    "            \"(%)\": accuracy_category,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Convert to DataFrame for easy display\n",
    "report_df = pd.DataFrame(report_data)\n",
    "\n",
    "# Add a row for the total F1 score (this will not be a weighted score, so it's not directly comparable)\n",
    "report_df.loc[\"Total\"] = report_df.sum(numeric_only=True)\n",
    "report_df.loc[\"Total\", \"Category\"] = \"Total\"\n",
    "report_df.loc[\"Total\", \"(%)\"] = f1\n",
    "\n",
    "# Print the report table\n",
    "print(report_df)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Category  Total  Correct  Incorrect       (%)\n",
      "0         forest   97.0      2.0       95.0  0.020619\n",
      "1      buildings   89.0      6.0       83.0  0.067416\n",
      "2        glacier  102.0     75.0       27.0  0.735294\n",
      "3         street  110.0      4.0      106.0  0.036364\n",
      "4       mountain  110.0     12.0       98.0  0.109091\n",
      "5            sea   92.0      6.0       86.0  0.065217\n",
      "Total      Total  600.0    105.0      495.0  0.169079\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
